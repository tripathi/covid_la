{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For scraping\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "#For geojson\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import math\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily scrape of LA County Public Health table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose what to scrape\n",
    "archive = False\n",
    "titlestring='1206'\n",
    "stringprint='12/06/20'\n",
    "\n",
    "if archive:     \n",
    "    url = 'data/'+titlestring+'.html' #Uses locally downloaded file from wayback machine to lookup archived site\n",
    "    soup = BeautifulSoup(open(url),\"html.parser\")\n",
    "else:\n",
    "    url ='http://publichealth.lacounty.gov/media/Coronavirus/locations.htm'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#    datetime.today().strftime('%Y-%m-%d')\n",
    "#    titlestring=datetime.today().strftime('%m%d') #Use today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liout = soup.find_all('table', {'class' : 'overflow-y'})\n",
    "alltables = pd.read_html(str(liout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = alltables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0] = df.iloc[:,0].str.replace('--','suppressed')\n",
    "#df.iloc[:,0] = df.iloc[:,0].str.replace('City of ','')\n",
    "#df.iloc[:,0] = df.iloc[:,0].str.replace('Unincorporated - ','')\n",
    "#df.iloc[:,0] = df.iloc[:,0].str.replace('Los Angeles - ','')\n",
    "df.iloc[:,0] = df.iloc[:,0].str.replace('*','')\n",
    "#df.iloc[:,0] = df.iloc[:,0].str.replace('- ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add two blank rows for Total and Pasadena\n",
    "df.loc[len(df)]=''\n",
    "df.loc[len(df)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liout2 = soup.find_all('table', {'class' : 'table table-striped table-bordered table-sm'})[0].find_all('td')\n",
    "#summary = pd.read_html(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"CITY/COMMUNITY**\": \"Locations\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add total - currently hardcoded\n",
    "column_marker =0 \n",
    "for column in soup.find_all('thead', {'class' : 'bg-dark'})[1].find_all('td'): \n",
    "\n",
    "    if (column_marker==0):\n",
    "        print('Renaming ', column.get_text(), 'to Total')\n",
    "        df.iat[-1, column_marker] = 'Total'\n",
    "    else:\n",
    "        df.iat[-1, column_marker] = column.get_text()\n",
    "        print(column.get_text())\n",
    "    column_marker += 1\n",
    "\n",
    "#df.iat[-1, 3] = int(soup.find_all('tr')[11].find_all('td')[1].get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('tr')[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Pasadena back in \n",
    "column_marker =0\n",
    "pasadenapop = 141371.\n",
    "for column in soup.find_all('tr')[11].find_all('td'):\n",
    "    print(column.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Pasadena back in \n",
    "#column_marker =0\n",
    "pasadenapop = 141371.\n",
    "#for column in soup.find_all('tr')[8].find_all('td'): #Previously 4, change as of May ~15\n",
    "#    if(column_marker <2):\n",
    "#        print(column.get_text())\n",
    "#        df.iat[-3, column_marker] = column.get_text().replace('-','').replace(' ','')\n",
    "#        if(column_marker ==1):\n",
    "#            df.iat[-3, column_marker+1] = int( column.get_text().replace('-','')) /pasadenapop *100000\n",
    "#    else:\n",
    "#        print('Skipping:', column.get_text())\n",
    "#    column_marker += 1\n",
    "df.iat[-3, 0] = 'City of Pasadena'#soup.find_all('tr')[7].find_all('td')[0].get_text().replace('-','').replace(' ','')\n",
    "df.iat[-3, 1] = int(soup.find_all('tr')[7].find_all('td')[1].get_text())\n",
    "df.iat[-3, 2] = int(soup.find_all('tr')[7].find_all('td')[1].get_text())/pasadenapop *100000\n",
    "df.iat[-3, 3] = int(soup.find_all('tr')[11].find_all('td')[1].get_text())\n",
    "df.iat[-3, 4] = int(soup.find_all('tr')[11].find_all('td')[1].get_text())/pasadenapop *100000    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Long Beach back in (No longer in table list like it was before)\n",
    "#df.at['Long Beach',colnames[1]] = soup.find_all('tr')[7].find_all('td')[1].text.replace('*','') #Previously 3, not 7\n",
    "#df.at['Long Beach',colnames[2]] = int(soup.find_all('tr')[7].find_all('td')[1].text)/longbeachpop*100000\n",
    "\n",
    "#column_marker =0\n",
    "longbeachpop = 467354.\n",
    "#for column in soup.find_all('tr')[7].find_all('td'): #Previously 4, change as of May ~15\n",
    "#    if(column_marker <2):\n",
    "#        print(column.get_text())\n",
    "#        df.iat[-2, column_marker] = column.get_text().replace('- ','')\n",
    "#        if(column_marker ==1):\n",
    "#            df.iat[-2, column_marker+1] = int( column.get_text().replace('- ','')) /longbeachpop *100000\n",
    "#    else:\n",
    "#        print('Skipping:', column.get_text())\n",
    "#    column_marker += 1\n",
    "df.iat[-2, 0] = 'City of Long Beach'\n",
    "df.iat[-2, 1] = int(soup.find_all('tr')[6].find_all('td')[1].get_text())\n",
    "df.iat[-2, 2] = int(soup.find_all('tr')[6].find_all('td')[1].get_text())/longbeachpop *100000\n",
    "df.iat[-2, 3] = int(soup.find_all('tr')[10].find_all('td')[1].get_text())\n",
    "df.iat[-2, 4] = int(soup.find_all('tr')[10].find_all('td')[1].get_text())/longbeachpop *100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('tr')[7].find_all('td')[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other cleanup - this is different once the index has been changed:\n",
    "df.loc[df['Locations'].str.contains('Under Investigation'), 'Locations'] = 'Under Investigation'\n",
    "#df.loc[df['Locations'].str.match('Los Angeles'), 'Locations'] = 'Los Angeles - AGGREGATE'\n",
    "df.loc[df['Locations'].str.match('Laboratory Confirmed Cases (LCC)'), 'Locations'] = 'Total'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[df['Locations'].str.contains('AGGREGATE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Locations', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fix Long Beach and Pasadena\n",
    "column_marker = 0\n",
    "for column in soup.find_all('tr')[3].find_all('td'):\n",
    "    print(df.loc['Long Beach'])\n",
    "    df.at['Long Beach', colnames[column_marker]] = column.get_text()\n",
    "    #    df.iat[df.loc['Long Beach'] , column_marker] = column.get_text()\n",
    "    #    print('Before', df[df['Locations'].str.contains('Long Beach')])\n",
    "    #    df.iat[df.index(df['Locations'].str.contains('Long Beach')).tolist(), column_marker] = column.get_text()\n",
    "    column_marker += 1\n",
    "    #    print('After', df[df['Locations'].str.contains('Long Beach')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['City of Long Beach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out to CSV. Make the format match what covid_la.ipynb expects\n",
    "df.index.names=['city']\n",
    "df.rename(columns={'Locations': 'city', 'Total Cases': 'count', 'Rate': 'rate'}).to_csv(\n",
    "    \"./data/covid_bos_\"+titlestring+\".csv\",\n",
    "    index=True,\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "#THERE IS A KNOWN BUG that Under Investigation is dropped in archived scrapes! Must be readded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in LA neighborhood map\n",
    "nbd= gpd.read_file(\"data/bos_stat_areas.geojson\")\n",
    "\n",
    "#Drop islands\n",
    "nbd=nbd[~nbd.label.str.contains('Catalina')]\n",
    "nbd=nbd[~nbd.label.str.contains('Clemente')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary \n",
    "# key = old name \n",
    "# value = new name \n",
    "\n",
    "\n",
    "dict = {'Cases':'Confirmed Cases as of '+stringprint,\n",
    "        'Case Rate1':'Infection rate adjusted for population (#/100,000)',\n",
    "        'Deaths':'Attributed Deaths',\n",
    "        'Death Rate2':'Death rate adjusted for population (#/100,000)'} \n",
    "  \n",
    "# call rename () method \n",
    "df.rename(columns=dict, \n",
    "          inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('Unincorporated - Santa Catalina Island', axis=0)\n",
    "#df.drop('Unincorporated - San Clemente Island', axis=0)\n",
    "mymerged = nbd.set_index('label').join(df)\n",
    "mymerged.to_file(\"./data/combined_reports_reg_bos_\"+titlestring+\".json\",index=True, driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
